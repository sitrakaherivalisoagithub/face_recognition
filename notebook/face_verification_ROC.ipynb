{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceba4d8e",
   "metadata": {},
   "source": [
    "# Analyse ROC et Visualisation des Distances\n",
    "Ce notebook permet de visualiser la distribution des distances entre paires ancrage-positive et ancrage-négative, et de tracer la courbe ROC pour guider le choix d'un seuil de similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd070ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.herivalisoa\\PycharmProjects\\FaceAttendanceProject\\venv\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\s.herivalisoa/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\s.herivalisoa/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\s.herivalisoa/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\s.herivalisoa/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\s.herivalisoa/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Initialisation du modèle\n",
    "app = FaceAnalysis(name=\"buffalo_l\")\n",
    "\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68b103ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>id1</th>\n",
       "      <th>pos</th>\n",
       "      <th>id2</th>\n",
       "      <th>neg</th>\n",
       "      <th>id3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>056279.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>108998.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>030848.jpg</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>024091.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>000023.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>093653.jpg</td>\n",
       "      <td>9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122082.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>045833.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>188283.jpg</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110393.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>021233.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>178433.jpg</td>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101388.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>056784.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>105432.jpg</td>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anchor  id1         pos  id2         neg   id3\n",
       "0  056279.jpg    1  108998.jpg    1  030848.jpg   496\n",
       "1  024091.jpg    1  000023.jpg    1  093653.jpg  9313\n",
       "2  122082.jpg    3  045833.jpg    3  188283.jpg  7200\n",
       "3  110393.jpg    3  021233.jpg    3  178433.jpg  4643\n",
       "4  101388.jpg    4  056784.jpg    4  105432.jpg  2988"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le fichier triplet CSV\n",
    "df = pd.read_csv(\"../static/triplets.csv\", sep=',')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b9843cd-36ac-4cfc-b09f-3c1676d369d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc1fa50-4e2b-410f-b34c-4e399f094b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de0597da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(image_path):\n",
    "    full_path = os.path.join(\"../static/triplets_images\", image_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        return None\n",
    "    #img = np.array(Image.open(full_path).convert(\"RGB\"))\n",
    "    img = cv2.imread(full_path)\n",
    "    print(img.shape)\n",
    "    # Resize si trop petit\n",
    "    if img.shape[0] < 160 or img.shape[1] < 160:\n",
    "        img = cv2.resize(img, (224, 224))  # ou (224, 224)\n",
    "    print(img.shape)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = app.get(img)\n",
    "    if not faces:\n",
    "        print(\"Not found\")\n",
    "    return faces[0].embedding if faces else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1a738c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9470\n",
      "(116, 82, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(117, 84, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(118, 84, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "9257\n",
      "(110, 78, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(137, 103, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(121, 88, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "10714\n",
      "(110, 84, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(110, 81, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(115, 89, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "5096\n",
      "(107, 80, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(122, 81, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(118, 90, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "8484\n",
      "(128, 92, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(110, 81, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(111, 83, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "12265\n",
      "(117, 84, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(120, 88, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(102, 74, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "2187\n",
      "(120, 87, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(108, 85, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(119, 87, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "568\n",
      "(114, 82, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(110, 83, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(114, 84, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "1816\n",
      "(116, 84, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(113, 82, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(113, 85, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "2111\n",
      "(113, 86, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(123, 90, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n",
      "(111, 83, 3)\n",
      "(224, 224, 3)\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "distances, labels = [], []\n",
    "\n",
    "for _, row in df_1.iterrows():\n",
    "    print(_)\n",
    "    emb_anchor = get_embedding(row['anchor'])\n",
    "    emb_pos = get_embedding(row['pos'])\n",
    "    emb_neg = get_embedding(row['neg'])\n",
    "\n",
    "    if emb_anchor is not None and emb_pos is not None:\n",
    "        d_ap = cosine_distances([emb_anchor], [emb_pos])[0][0]\n",
    "        distances.append(d_ap)\n",
    "        labels.append(1)  # Positive\n",
    "\n",
    "    if emb_anchor is not None and emb_neg is not None:\n",
    "        d_an = cosine_distances([emb_anchor], [emb_neg])[0][0]\n",
    "        distances.append(d_an)\n",
    "        labels.append(0)  # Negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56032c77-11ba-4b8f-bf98-e6e7465fb6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1666eec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Tracer histogrammes + courbe ROC\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\PycharmProjects\\FaceAttendanceProject\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\FaceAttendanceProject\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1163\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1060\u001b[0m     {\n\u001b[0;32m   1061\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m ):\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \n\u001b[0;32m   1074\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1163\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\FaceAttendanceProject\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:901\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    898\u001b[0m threshold_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[distinct_value_indices, y_true\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# accumulate the true positives with decreasing threshold\u001b[39;00m\n\u001b[1;32m--> 901\u001b[0m tps \u001b[38;5;241m=\u001b[39m \u001b[43mstable_cumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m[threshold_idxs]\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;66;03m# express fps as a cumsum to ensure fps is increasing even in\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# the presence of floating point errors\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     fps \u001b[38;5;241m=\u001b[39m stable_cumsum((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m weight)[threshold_idxs]\n",
      "File \u001b[1;32m~\\PycharmProjects\\FaceAttendanceProject\\venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:1238\u001b[0m, in \u001b[0;36mstable_cumsum\u001b[1;34m(arr, axis, rtol, atol)\u001b[0m\n\u001b[0;32m   1235\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1236\u001b[0m expected \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[1;32m-> 1238\u001b[0m     \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m, expected, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m ):\n\u001b[0;32m   1240\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1241\u001b[0m         (\n\u001b[0;32m   1242\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumsum was found to be unstable: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    }
   ],
   "source": [
    "# Tracer histogrammes + courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(labels, distances, pos_label=0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist([d for l, d in zip(labels, distances) if l == 1], bins=30, alpha=0.6, label='Positive')\n",
    "plt.hist([d for l, d in zip(labels, distances) if l == 0], bins=30, alpha=0.6, label='Negative')\n",
    "plt.title(\"Distribution des distances\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], '--', color='gray')\n",
    "plt.title(\"Courbe ROC\")\n",
    "plt.xlabel(\"Taux de faux positifs (FPR)\")\n",
    "plt.ylabel(\"Taux de vrais positifs (TPR)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcabbf7-f339-4a3d-9342-1eafb7a92158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
